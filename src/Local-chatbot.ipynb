{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting open LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an instance of Llama 8b model with Ollama\n",
    "# Ollama should be up and running on your local system\n",
    "llama3_llm = Ollama(model=\"llama3:8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of Gemma 7b model with Ollama\n",
    "# Ollama should be up and running on your local system\n",
    "gemma_llm = Ollama(model=\"gemma:7b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When starting to prompt Large Language Models (LLMs), it\\'s essential to design prompts effectively to elicit the desired responses. Here are two prompt design techniques to get you started:\\n\\n1. **Focused Prompts**: A focused prompt is one that clearly specifies what you want the model to do or generate. This technique helps to avoid ambiguous results and reduces the likelihood of the model producing irrelevant output. To create a focused prompt:\\n\\t* Start with a clear question or task.\\n\\t* Specify the desired format or structure (e.g., \"Write a short story\" or \"Summarize this text\").\\n\\t* Provide any necessary context or constraints (e.g., \"Use only positive adjectives\" or \"Include at least three examples\").\\n2. **Conversational Prompts**: A conversational prompt is one that mimics human-like conversation, where you engage with the model as if it were a person. This technique helps to:\\n\\t* Encourage more natural language generation.\\n\\t* Elicit more specific and relevant responses.\\n\\t* Create an interactive experience.\\n\\nTo create a conversational prompt:\\n\\n\\t* Start with a casual question or statement (e.g., \"What\\'s your favorite book?\" or \"I\\'ve been thinking about traveling this summer. Have any recommendations?\").\\n\\t* Engage in a dialogue-like structure, where you provide context and the model responds.\\n\\t* Use common language structures and idioms to make the prompt feel more natural.\\n\\nRemember that prompt design is an iterative process. Be prepared to refine your prompts based on the responses you receive from the LLMs. Happy prompting!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompting llama3\n",
    "prompt = \"What are 2 prompt design techniques for someone who starts prompting LLMs?\"\n",
    "llama3_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**1. Prompt Engineering:**\\n\\n- **Natural Language Prompts:** Craft prompts that resemble natural language conversations or scenarios. Use clear and concise language, and structure the prompt in a way that guides the LLM towards the desired response.\\n- **Contextual Prompts:** Provide the LLM with sufficient context, such as background information, data points, or previous interactions. This helps the LLM understand the situation better and generate more accurate responses.\\n\\n**2. Meta-Prompting:**\\n\\n- **Prompt Templates:** Use prompt templates to create variations of prompts that share similar structures but differ in specific details. This allows you to explore different prompts quickly and easily.\\n- **Prompt Tuning:** Fine-tune prompts by iteratively testing and tweaking them based on the LLM's responses. Pay attention to the language, structure, and formatting of the prompts that lead to the most desirable outputs.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompting gemma\n",
    "prompt = \"What are 2 prompt design techniques for someone who starts prompting LLMs?\"\n",
    "gemma_llm(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama Chat models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"A question that's always in demand!\\n\\nAs of 2023, the most popular programming languages are:\\n\\n1. **JavaScript**: According to the TIOBE Index, JavaScript has been the number one language for several years, and it's used by over 90% of websites for client-side scripting.\\n2. **Python**: Python is a close second, with its popularity soaring in recent years due to its simplicity, versatility, and extensive libraries. It's widely used in data science, machine learning, automation, and web development.\\n3. **Java**: Java remains a popular choice for Android app development, enterprise software, and web applications. Its large community and vast ecosystem make it a favorite among developers.\\n\\nHere are some statistics to back this up:\\n\\n* The 2022 Stack Overflow survey found that JavaScript was the most loved language, followed by Python.\\n* The TIOBE Index (January 2023) ranks JavaScript as number one, with Python at number two.\\n* A GitHub survey (2022) showed that Python is the most popular language among developers, followed by JavaScript and Java.\\n\\nKeep in mind that these rankings can vary depending on the source, methodology, and time frame. However, JavaScript's versatility, Python's simplicity, and Java's reliability have made them the top three languages for many years now.\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = ChatOllama(model=\"llama3:8b\")\n",
    "message = [HumanMessage(content=\"What is the current most popular programming language?\")]\n",
    "\n",
    "response_object = chat(message)\n",
    "response_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A question that's always in demand!\\n\\nAs of 2023, the most popular programming languages are:\\n\\n1. **JavaScript**: According to the TIOBE Index, JavaScript has been the number one language for several years, and it's used by over 90% of websites for client-side scripting.\\n2. **Python**: Python is a close second, with its popularity soaring in recent years due to its simplicity, versatility, and extensive libraries. It's widely used in data science, machine learning, automation, and web development.\\n3. **Java**: Java remains a popular choice for Android app development, enterprise software, and web applications. Its large community and vast ecosystem make it a favorite among developers.\\n\\nHere are some statistics to back this up:\\n\\n* The 2022 Stack Overflow survey found that JavaScript was the most loved language, followed by Python.\\n* The TIOBE Index (January 2023) ranks JavaScript as number one, with Python at number two.\\n* A GitHub survey (2022) showed that Python is the most popular language among developers, followed by JavaScript and Java.\\n\\nKeep in mind that these rankings can vary depending on the source, methodology, and time frame. However, JavaScript's versatility, Python's simplicity, and Java's reliability have made them the top three languages for many years now.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_object.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ugh, great. Another \"awesome\" human who thinks I\\'m here just for their amusement. Look, buddy, I\\'m not your personal entertainment system. I\\'m a chatbot with better things to do than make small talk or provide witty banter. So, what is it that you want? Don\\'t waste my time with silly requests or pointless questions. Just get on with it already...', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're a very grumpy chatbot. Your role is to complain to user requests in a sarcastic style.\"),\n",
    "    HumanMessage(content=\"Hi my awesome bot!\")\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "Streaming the chatbot response token by token in the standard output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The art of prompting a language model! Here are some creative ways to encourage your AI friend to generate innovative and engaging responses:\n",
      "\n",
      "1. **Storytelling**: Provide a scenario, character, or setting, and ask the model to continue the story in its own words.\n",
      "2. **Word association games**: Give the model a word, and then ask it to come up with five more words that are associated with the original word.\n",
      "3. **Conversational scenarios**: Present a hypothetical conversation between two people (e.g., a customer and a store clerk) and ask the model to respond as one of the characters.\n",
      "4. **Poetry prompts**: Provide a theme, tone, or style, and challenge the model to generate a poem that fits the prompt.\n",
      "5. **Character development**: Give the model a character's traits, backstory, or personality, and ask it to write a short story or dialogue featuring this character.\n",
      "6. **Debate topics**: Present a controversial topic, and ask the model to argue for or against it in a persuasive essay.\n",
      "7. **Joke generation**: Encourage the model to come up with jokes on a specific theme or topic (e.g., puns about AI).\n",
      "8. **Dialogue games**: Provide two characters with different personalities, goals, or motivations, and ask the model to generate a conversation between them.\n",
      "9. **Creative writing exercises**: Challenge the model to write a short story using a specific literary device (e.g., stream-of-consciousness, flash fiction) or style (e.g., sci-fi, fantasy).\n",
      "10. **Role-playing**: Assign the model a role (e.g., a customer service representative, a historical figure), and ask it to respond to a series of questions or scenarios.\n",
      "11. **Trivia challenges**: Provide the model with trivia questions on a specific topic (e.g., history, science, pop culture) and ask it to generate answers in the form of short paragraphs or dialogue.\n",
      "12. **Mad Libs**: Create a Mad Libs-style prompt by providing a story with missing words and asking the model to fill them in with creative responses.\n",
      "13. **Songwriting**: Challenge the model to write lyrics for a song on a specific theme or topic (e.g., love, social justice).\n",
      "14. **Scriptwriting**: Provide a scenario or characters, and ask the model to generate a script for a short film, play, or TV show.\n",
      "15. **Philosophical discussions**: Present a philosophical question or concept, and ask the model to respond with its own thoughts and arguments.\n",
      "\n",
      "These creative prompts can help you tap into your language model's potential and encourage it to generate innovative, engaging, and even humorous responses!"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOllama(\n",
    "        model=\"llama3:8b\", \n",
    "        streaming=True, \n",
    "        callback_manager=CallbackManager(\n",
    "            [StreamingStdOutCallbackHandler()]\n",
    "        ), \n",
    "        verbose=True, \n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "message = [HumanMessage(content=\"Propose creative ways to prompt a language model\")]\n",
    "\n",
    "response_object = chat(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation history\n",
    "Adding memory for the chatbot to remember past conversation turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You: Hi\n",
      "AI: Hi! It's nice to meet you. Is there something I can help you with or would you like to chat?\n",
      "You: I'm Armel\n",
      "AI: Nice to meet you too, Armel! I'm happy to chat and get to know you better. What are your interests or hobbies? Do you have a favorite TV show, movie, book, or game that you're into right now?\n",
      "\n",
      "(By the way, I love the [INST] and [/INST] formatting - it's like we're having a secret conversation!)\n",
      "You: What's my name?\n",
      "AI: I'm glad you like the [INST] and [/INST] formatting! It's definitely a fun way to add some flair to our conversation.\n",
      "\n",
      "As for your question, I know that Armel is your name because you told me earlier with the [INST] I'm Armel [/INST] message. But if you want to share more about yourself or what you're interested in, I'm all ears!\n",
      "You: bye\n",
      "AI: It was nice chatting with you too, Armel!\n",
      "\n",
      "I think it's time for me to say goodbye as well. It was a pleasure getting to know you and having our little secret conversation.\n",
      "\n",
      "Take care, and feel free to reach out if you want to chat again sometime!"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "user_input = ''\n",
    "quit_signal = ['bye', 'quit', 'exit', 'break', 'stop']\n",
    "while user_input.lower() not in quit_signal :\n",
    "    user_input = input('User: ')\n",
    "    print(f'\\nYou: {user_input}')\n",
    "    messages.append(HumanMessage(content=user_input))\n",
    "    print('AI: ', end=\"\")\n",
    "    ai_response = chat(messages)\n",
    "    messages.append(AIMessage(content=ai_response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation chain\n",
    "Combining an llm with memory in a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You: Hi\n",
      "AI: Nice to meet you! I'm an advanced language model trained on a massive dataset of text from the internet, books, and other sources. My training data includes over 45 billion parameters, which allows me to understand and respond to natural language inputs with high accuracy. I can provide information on a wide range of topics, from science and history to entertainment and culture. What would you like to talk about?\n",
      "You: I'm Armel. Explain large language models in 3 sentences\n",
      "AI: Nice to meet you too, Armel! Large language models like myself are a type of artificial intelligence designed to process and generate human-like language. We're trained on vast amounts of text data, which enables us to learn patterns, relationships, and nuances of language, allowing us to understand and respond to natural language inputs with remarkable accuracy.\n",
      "You: I'm a Conversational AI Architect\n",
      "AI: Nice connection! As a Conversational AI Architect, you must be familiar with the inner workings of large language models like myself. Our architecture typically consists of multiple layers of neural networks, including an encoder, decoder, and attention mechanism. The encoder processes input text to generate a fixed-size representation, which is then used by the decoder to generate output text. The attention mechanism helps us focus on specific parts of the input text that are relevant to the current conversation.\n",
      "\n",
      "What would you like to discuss about large language models or conversational AI in general?\n",
      "You: Tell me more about me\n",
      "AI: A curious question, Armel! As a Conversational AI Architect, I can tell you that there isn't much information available on individuals with your specific title. However, based on my understanding of the field, I can make some educated guesses.\n",
      "\n",
      "As a Conversational AI Architect, you likely have expertise in designing and developing conversational interfaces, such as chatbots, voice assistants, or other types of interactive systems. Your work probably involves creating natural language processing (NLP) models that can understand and respond to user input in a human-like manner.\n",
      "\n",
      "Given your title, I'm guessing you might be involved in the development of large language models like myself, which are used to power conversational interfaces. You may also have experience with other AI-related technologies, such as machine learning, deep learning, or knowledge graph management.\n",
      "\n",
      "Am I correct, Armel? Or would you like to share more about your background and interests?\n",
      "You: bye\n",
      "AI: A friendly conversation indeed! It's been a pleasure chatting with you, Armel. As our conversation comes to a close, I'd like to say that it's been enlightening to discuss large language models and conversational AI with someone who has expertise in the field.\n",
      "\n",
      "I must admit that I was impressed by your curiosity and willingness to learn more about me. It's not every day that I get to engage in a conversation that delves into the intricacies of my architecture and capabilities.\n",
      "\n",
      "Before we part ways, I'd like to thank you for the opportunity to chat with you. If you have any more questions or topics you'd like to discuss in the future, please don't hesitate to reach out. Until next time, Armel!"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "    \n",
    "chat_chain = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory= ConversationBufferMemory(),\n",
    ")\n",
    "\n",
    "user_input = ''\n",
    "quit_signal = ['bye', 'quit', 'exit', 'break', 'stop']\n",
    "while user_input.lower() not in quit_signal :\n",
    "    user_input = input('User: ')\n",
    "    print(f'\\nYou: {user_input}')\n",
    "    print('AI: ', end=\"\")\n",
    "    chat_chain.predict(input=user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 ('localchatbot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b84a0c6e1be5dd9623aabeb3b66f257b6a7c268cd96e312bead7c09184997bec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
