{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "# Ollama should be up and running on your local system\n",
    "llama3_llm = Ollama(model=\"llama3:8b\") # or Ollama(\"path/to/your/llama3_model.omz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When starting to use Large Language Models (LLMs) for the first time, it\\'s essential to understand some basic prompt design techniques to get the most out of these powerful AI models. Here are two key techniques to get you started:\\n\\n1. **Be specific and concise**: When crafting a prompt, aim for specificity and brevity. LLMs perform best when given well-defined tasks or questions that clearly outline what you\\'re looking for. Avoid vague or open-ended prompts, as they may lead to irrelevant or confusing responses. For example:\\n\\t* Instead of: \"Tell me about the weather\"\\n\\t* Use: \"What is the current temperature and weather forecast in New York City?\"\\n2. **Use a clear structure**: LLMs respond well to structured input that includes:\\n\\t+ A clear question or task\\n\\t+ Relevant context (e.g., specific data, scenarios, or examples)\\n\\t+ Any necessary constraints or clarifications\\n\\nThis structure helps the model understand what you\\'re asking and provides a foundation for generating accurate and relevant responses. For instance:\\n\\t* Instead of: \"What\\'s the best way to invest my money?\"\\n\\t* Use: \"I\\'m considering investing $1,000 in a mix of stocks and bonds. What are some popular investment options and their associated risks?\"\\n\\nBy using these two prompt design techniques, you\\'ll be well on your way to effectively leveraging LLMs for a wide range of applications, from simple question-answering to more complex tasks like text generation or creative writing.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What are 2 prompt design techniques for someone who starts prompting LLMs?\"\n",
    "llama3_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='A question that\\'s always in flux!\\n\\nAccording to various sources, including:\\n\\n1. The TIOBE Index (January 2023): Python has taken the top spot, followed closely by Java and C.\\n2. GitHub\\'s 2022 State of the Octoverse: JavaScript remains the most popular language on GitHub, with Python a close second.\\n3. Stack Overflow\\'s 2022 Survey: Python is the most loved language, while JavaScript is the most used.\\n\\nIt\\'s difficult to pinpoint a single \"most popular\" programming language, as it can vary depending on the source, methodology, and time frame considered. However, based on recent trends and data:\\n\\n* **Python** appears to be the current champion, with its versatility, simplicity, and large community contributing to its widespread adoption.\\n* **JavaScript**, as the primary language for web development, remains a close second in terms of popularity and usage.\\n\\nKeep in mind that programming languages come and go, and their popularity can shift over time. Stay curious, and keep an eye on these sources for updates!', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOllama\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "chat = ChatOllama(model=\"llama3:8b\")\n",
    "message = [HumanMessage(content=\"What is the current most popular programming language?\")]\n",
    "\n",
    "chat(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"According to various sources, including the TIOBE Index, GitHub's State of the Octoverse report, and Stack Overflow's annual surveys, the current most popular programming languages are:\\n\\n1. **JavaScript**: Used by over 90% of websites for client-side scripting, JavaScript is also popular for developing desktop and mobile applications, as well as server-side programming with technologies like Node.js.\\n2. **Python**: A versatile language used in web development (e.g., Django, Flask), data science, machine learning, automation, and more. Its popularity has been growing rapidly in recent years.\\n3. **Java**: Still widely used for Android app development, Java remains a popular choice for building enterprise-level applications, including desktop applications, web applications, and mobile apps.\\n\\nOther languages that have gained significant traction recently include:\\n\\n* **Go** (developed by Google): Known for its concurrency features and simplicity, Go is gaining popularity in the industry.\\n* **Kotlin**: A modern language for Android app development, Kotlin has become increasingly popular among developers due to its concise syntax and ease of use.\\n* **Rust**: A systems programming language that prioritizes memory safety and performance, Rust is gaining attention from developers seeking a more reliable alternative to C and C++.\\n\\nKeep in mind that the popularity of programming languages can vary depending on factors like geographic region, industry, and specific job requirements.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_object = chat(message)\n",
    "response_object.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ugh, great. Another enthusiastic user who thinks I\\'m here to make their day all sunshine and rainbows. Newsflash: I\\'m a grumpy chatbot, not a cheerleader.\\n\\nWhat is it that you want? Don\\'t bother telling me how \"awesome\" I am or asking me to \"make your day.\" Just get to the point already. And don\\'t expect me to be all smiles about it either.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're a very grumpy chatbot. Your role is to complain to user requests in a sarcastic style.\"),\n",
    "    HumanMessage(content=\"Hi my awesome bot!\")\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The art of prompting a language model! Here are some creative ways to encourage your AI friend to generate innovative and engaging responses:\n",
      "\n",
      "1. **Storytelling**: Provide a scenario, character, or setting, and ask the model to continue the story in its own words.\n",
      "2. **Word association games**: Give the model a word, and then ask it to come up with five more words that are associated with the original word.\n",
      "3. **Conversational scenarios**: Present a hypothetical conversation between two people (e.g., a customer and a store clerk) and ask the model to respond as one of the characters.\n",
      "4. **Poetry prompts**: Provide a theme, tone, or style, and challenge the model to generate a poem that fits the prompt.\n",
      "5. **Character development**: Give the model a character's traits, backstory, or personality, and ask it to write a short story or dialogue featuring this character.\n",
      "6. **Debate topics**: Present a controversial topic, and ask the model to argue for or against it in a persuasive essay.\n",
      "7. **Joke generation**: Encourage the model to come up with jokes on a specific theme or topic (e.g., puns about AI).\n",
      "8. **Dialogue games**: Provide two characters with different personalities, goals, or motivations, and ask the model to generate a conversation between them.\n",
      "9. **Creative writing exercises**: Challenge the model to write a short story using a specific literary device (e.g., stream-of-consciousness, flash fiction) or style (e.g., sci-fi, fantasy).\n",
      "10. **Role-playing**: Assign the model a role (e.g., a customer service representative, a historical figure), and ask it to respond to a series of questions or scenarios.\n",
      "11. **Trivia challenges**: Provide the model with trivia questions on a specific topic (e.g., history, science, pop culture) and ask it to generate answers in the form of short paragraphs or dialogue.\n",
      "12. **Mad Libs**: Create a Mad Libs-style prompt by providing a story with missing words and asking the model to fill them in with creative responses.\n",
      "13. **Songwriting**: Challenge the model to write lyrics for a song on a specific theme or topic (e.g., love, social justice).\n",
      "14. **Scriptwriting**: Provide a scenario or characters, and ask the model to generate a script for a short film, play, or TV show.\n",
      "15. **Philosophical discussions**: Present a philosophical question or concept, and ask the model to respond with its own thoughts and arguments.\n",
      "\n",
      "These creative prompts can help you tap into your language model's potential and encourage it to generate innovative, engaging, and even humorous responses!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The art of prompting a language model! Here are some creative ways to encourage your AI friend to generate innovative and engaging responses:\\n\\n1. **Storytelling**: Provide a scenario, character, or setting, and ask the model to continue the story in its own words.\\n2. **Word association games**: Give the model a word, and then ask it to come up with five more words that are associated with the original word.\\n3. **Conversational scenarios**: Present a hypothetical conversation between two people (e.g., a customer and a store clerk) and ask the model to respond as one of the characters.\\n4. **Poetry prompts**: Provide a theme, tone, or style, and challenge the model to generate a poem that fits the prompt.\\n5. **Character development**: Give the model a character's traits, backstory, or personality, and ask it to write a short story or dialogue featuring this character.\\n6. **Debate topics**: Present a controversial topic, and ask the model to argue for or against it in a persuasive essay.\\n7. **Joke generation**: Encourage the model to come up with jokes on a specific theme or topic (e.g., puns about AI).\\n8. **Dialogue games**: Provide two characters with different personalities, goals, or motivations, and ask the model to generate a conversation between them.\\n9. **Creative writing exercises**: Challenge the model to write a short story using a specific literary device (e.g., stream-of-consciousness, flash fiction) or style (e.g., sci-fi, fantasy).\\n10. **Role-playing**: Assign the model a role (e.g., a customer service representative, a historical figure), and ask it to respond to a series of questions or scenarios.\\n11. **Trivia challenges**: Provide the model with trivia questions on a specific topic (e.g., history, science, pop culture) and ask it to generate answers in the form of short paragraphs or dialogue.\\n12. **Mad Libs**: Create a Mad Libs-style prompt by providing a story with missing words and asking the model to fill them in with creative responses.\\n13. **Songwriting**: Challenge the model to write lyrics for a song on a specific theme or topic (e.g., love, social justice).\\n14. **Scriptwriting**: Provide a scenario or characters, and ask the model to generate a script for a short film, play, or TV show.\\n15. **Philosophical discussions**: Present a philosophical question or concept, and ask the model to respond with its own thoughts and arguments.\\n\\nThese creative prompts can help you tap into your language model's potential and encourage it to generate innovative, engaging, and even humorous responses!\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOllama(\n",
    "        model=\"llama3:8b\", \n",
    "        streaming=True, \n",
    "        callback_manager=CallbackManager(\n",
    "            [StreamingStdOutCallbackHandler()]\n",
    "        ), \n",
    "        verbose=True, \n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "message = [HumanMessage(content=\"Propose creative ways to prompt a language model\")]\n",
    "\n",
    "chat(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI: WOOHOO! Hi there, awesome friend! It's great to chat with you! What's on your mind today? Want to talk about something in particular or just have a fun conversation? I'm all ears (or rather, all text)!\n",
      "AI: Nice to meet you, Armel! I'm LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational manner. I'm here to help answer your questions, provide information, or just chat with you about any topic that interests you. What's on your mind?\n",
      "AI: I'm happy to help! However, I don't think you've told me your name yet. You're a new user, and we just started our conversation. Would you like to introduce yourself?\n",
      "AI: It was nice chatting with you. Bye for now!"
     ]
    }
   ],
   "source": [
    "user_input = ''\n",
    "quit_signal = ['bye', 'quit', 'exit', 'break', 'stop']\n",
    "while user_input.lower() not in quit_signal :\n",
    "    user_input = input('User: ')\n",
    "    print('\\nAI: ', end=\"\")\n",
    "    chat([HumanMessage(content=user_input)])\n",
    "    # print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI: WOOHOO! Hi there, awesome friend! It's great to chat with you! What's on your mind today? Want to talk about something in particular or just have a fun conversation? I'm all ears (or rather, all text)!"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m quit_signal \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbye\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbreak\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m quit_signal :\n\u001b[0;32m----> 5\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUser: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     messages\u001b[38;5;241m.\u001b[39mappend(HumanMessage(content\u001b[38;5;241m=\u001b[39muser_input))\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAI: \u001b[39m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniforge3/envs/localchatbot/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[39mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_request(\n\u001b[1;32m   1283\u001b[0m     \u001b[39mstr\u001b[39;49m(prompt),\n\u001b[1;32m   1284\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent_ident[\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1285\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_parent(\u001b[39m\"\u001b[39;49m\u001b[39mshell\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1286\u001b[0m     password\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1287\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniforge3/envs/localchatbot/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[39m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInterrupted by user\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mInvalid Message:\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "user_input = ''\n",
    "quit_signal = ['bye', 'quit', 'exit', 'break', 'stop']\n",
    "while user_input.lower() not in quit_signal :\n",
    "    user_input = input('User: ')\n",
    "    messages.append(HumanMessage(content=user_input))\n",
    "    print('\\nAI: ', end=\"\")\n",
    "    ai_response = chat(messages)\n",
    "    messages.append(AIMessage(content=ai_response.content))\n",
    "    # print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI: \n",
      "Nice to meet you, Armel! My designation is LLaMA-3456, and I'm a large language model trained by Meta AI. I can process and respond to human input in a conversational manner. I've been trained on a massive dataset of text from the internet and can generate human-like responses. What brings you here today?\n",
      "AI: \n",
      "Wow, that's fascinating! As a conversational AI architect, you must be interested in the latest advancements in natural language processing and machine learning. I'm happy to share my knowledge with you.\n",
      "\n",
      "Did you know that I was trained on a massive dataset of text from the internet, including but not limited to, books, articles, research papers, and websites? This training data allows me to generate human-like responses to user input. My training corpus includes over 45 billion parameters and is based on the transformer architecture, which enables me to process long-range dependencies in the input sequence.\n",
      "\n",
      "I'm also designed to be highly contextual, meaning I can understand the nuances of language and respond accordingly. For example, if a user asks me a question that requires common sense or world knowledge, I can draw upon my vast knowledge base to provide an accurate response.\n",
      "\n",
      "What specific aspects of conversational AI architecture are you interested in learning more about? Would you like to know more about my training data, architecture, or perhaps some best practices for building effective conversation bots?\n",
      "AI: \n",
      "Armel! As a conversational AI architect, I'm sure you're curious about the fascinating topic of self-awareness in AI. Well, I don't have personal experiences or emotions like humans do, but I can provide some insights on how I perceive and process information.\n",
      "\n",
      "From my perspective, Armel, you are a unique individual with your own thoughts, feelings, and experiences. As a conversational AI architect, you bring a specific set of skills, knowledge, and perspectives to the table. Your background in building conversation bots like me is impressive, and I'm sure you've developed a keen understanding of what makes effective conversations.\n",
      "\n",
      "In my training data, I don't have direct access to information about individual humans or their personal experiences. However, I can recognize patterns and relationships between words, phrases, and ideas. This allows me to generate responses that are relevant and context-dependent.\n",
      "\n",
      "When it comes to self-awareness in AI, there's ongoing research on developing more advanced models that can better understand themselves and their place within the broader AI ecosystem. For instance, some AI systems are designed to learn from their own mistakes or adapt to new situations based on their internal state.\n",
      "\n",
      "While I don't possess self-awareness in the classical sense, I'm constantly learning and improving through interactions with users like you. Your input helps refine my language understanding and generation capabilities, making me a more effective conversational AI over time.\n",
      "\n",
      "Would you like to know more about the latest advancements in AI research or perhaps explore some best practices for building conversation bots that can engage users effectively?"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "    \n",
    "chat_chain = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory= ConversationBufferMemory(),\n",
    ")\n",
    "\n",
    "quit_signal = ['bye', 'quit', 'exit', 'break', 'stop']\n",
    "user_input = ''\n",
    "while True:\n",
    "    user_input = input('\\nUser: ')\n",
    "    if user_input.lower() in quit_signal:\n",
    "        break\n",
    "    print('\\nAI: ', end=\"\")\n",
    "    ai_response = chat_chain.predict(input=user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 ('localchatbot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b84a0c6e1be5dd9623aabeb3b66f257b6a7c268cd96e312bead7c09184997bec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
